{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c1d6c0",
   "metadata": {},
   "source": [
    "\n",
    "# üå™Ô∏è Storm Damage Prediction ‚Äî End‚Äëto‚ÄëEnd Explainable Pipeline (Final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103cfb9d",
   "metadata": {},
   "source": [
    "\n",
    "This notebook builds a **production‚Äëstyle ML pipeline** that predicts **Property** and **Crop** damages from a natural‚Äëhazard dataset that includes **structured** fields and **unstructured narratives**.\n",
    "\n",
    "### What you get\n",
    "- ‚úÖ **Robust data cleaning** (drop ids, unify date/time, duration in seconds)\n",
    "- ‚úÖ **Geo feature engineering** (mean lat/lon, sin/cos, azimuths)\n",
    "- ‚úÖ **Text features from a pretrained LLM** (`SentenceTransformer: all-MiniLM-L6-v2`)\n",
    "- ‚úÖ **Models**: Ridge, XGBoost, TabTransformer (PyTorch) ‚Äî multi‚Äëoutput regression\n",
    "- ‚úÖ **Optuna hyperparameter tuning** (Random + Bayesian sampling)\n",
    "- ‚úÖ **Top‚Äë20 feature selection** via permutation importance (on preprocessed space)\n",
    "- ‚úÖ **Explainability**: SHAP global & local, LLM natural‚Äëlanguage explanations\n",
    "- ‚úÖ **Executive Summary** (LLM), **Dual‚ÄëTarget Explainability PDF report**\n",
    "- ‚úÖ All artifacts saved to `./artifacts_pipeline`\n",
    "\n",
    "> **Note**: This notebook expects the CSV file to be in the same folder:\n",
    "> `StormEvents_details-ftp_v1.0_d2013_c20250520.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd69e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 1) Config & Imports ===\n",
    "import os, re, json, math, gc, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Text embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "\n",
    "# Optional TabTransformer (rtdl). If missing, we fallback to MLPRegressor.\n",
    "USE_RTDL = True\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import rtdl\n",
    "except Exception as e:\n",
    "    print(\"‚ÑπÔ∏è rtdl/torch not available; will fallback to sklearn MLPRegressor for tabular deep model.\")\n",
    "    USE_RTDL = False\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# SHAP & plotting (for report section later)\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OpenAI for LLM explanations (optional)\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    OPENAI_READY = bool(os.getenv(\"OPENAI_API_KEY\"))\n",
    "except Exception:\n",
    "    OPENAI_READY = False\n",
    "\n",
    "# Reportlab for PDF\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image\n",
    "from reportlab.lib import colors\n",
    "\n",
    "# === Paths ===\n",
    "CSV_PATH = \"StormEvents_details-ftp_v1.0_d2013_c20250520.csv\"  # in same folder as notebook\n",
    "OUTDIR   = \"./artifacts_pipeline\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# === Text model ===\n",
    "EMBED_MODEL_NAME = \"all-MiniLM-L6-v2\"  # pretrained SentenceTransformer (LLM encoder)\n",
    "\n",
    "print(\"Config OK. Output dir:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e508f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 2) Helpers ===\n",
    "\n",
    "def parse_damage(v):\n",
    "    if pd.isna(v):\n",
    "        return np.nan\n",
    "    s = str(v).strip().upper().replace(\",\", \"\")\n",
    "    if s in (\"\", \"NA\", \"N/A\", \"NONE\"):\n",
    "        return np.nan\n",
    "    mult = 1.0\n",
    "    if s.endswith(\"K\"):\n",
    "        mult = 1e3; s = s[:-1]\n",
    "    elif s.endswith(\"M\"):\n",
    "        mult = 1e6; s = s[:-1]\n",
    "    elif s.endswith(\"B\"):\n",
    "        mult = 1e9; s = s[:-1]\n",
    "    try:\n",
    "        return float(s) * mult\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def to_dt(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, errors=\"coerce\", infer_datetime_format=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, errors=\"coerce\")\n",
    "\n",
    "def from_ymd_time_cols(df, side):\n",
    "    ym = df.get(f\"{side.upper()}_YEARMONTH\", pd.Series(index=df.index))\n",
    "    day = df.get(f\"{side.upper()}_DAY\", pd.Series(index=df.index))\n",
    "    hhmm = df.get(f\"{side.upper()}_TIME\", pd.Series(index=df.index))\n",
    "    if ym.isna().all() or day.isna().all() or hhmm.isna().all():\n",
    "        return None\n",
    "    ym = pd.to_numeric(ym, errors=\"coerce\").astype(\"Int64\")\n",
    "    day = pd.to_numeric(day, errors=\"coerce\").astype(\"Int64\")\n",
    "    hhmm = pd.to_numeric(hhmm, errors=\"coerce\").astype(\"Int64\")\n",
    "    def make_ts(row):\n",
    "        if pd.isna(row[0]) or pd.isna(row[1]) or pd.isna(row[2]):\n",
    "            return pd.NaT\n",
    "        y = int(row[0] // 100); m = int(row[0] % 100); d = int(row[1]); t = int(row[2])\n",
    "        HH = t // 100; MM = t % 100\n",
    "        try: return pd.Timestamp(year=y, month=m, day=d, hour=HH, minute=MM)\n",
    "        except: return pd.NaT\n",
    "    return pd.Series(list(map(make_ts, zip(ym, day, hhmm))), index=df.index)\n",
    "\n",
    "def duration_seconds(begin_ts, end_ts):\n",
    "    dt = (end_ts - begin_ts).dt.total_seconds()\n",
    "    return pd.to_numeric(dt, errors=\"coerce\")\n",
    "\n",
    "AZIMUTH_MAP = {\"N\":0,\"NNE\":22.5,\"NE\":45,\"ENE\":67.5,\"E\":90,\"ESE\":112.5,\"SE\":135,\"SSE\":157.5,\n",
    "               \"S\":180,\"SSW\":202.5,\"SW\":225,\"WSW\":247.5,\"W\":270,\"WNW\":292.5,\"NW\":315,\"NNW\":337.5}\n",
    "\n",
    "import math\n",
    "def metrics_frame(y_true, y_pred, labels):\n",
    "    out = {}\n",
    "    for i, name in enumerate(labels):\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        rmse = math.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i]))\n",
    "        r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "        out[name] = dict(MAE=mae, RMSE=rmse, R2=r2)\n",
    "    return pd.DataFrame(out).T\n",
    "\n",
    "print(\"Helper functions ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 3) Load & Clean ===\n",
    "assert os.path.exists(CSV_PATH), f\"CSV not found at {CSV_PATH}. Place it next to the notebook.\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, low_memory=False, encoding=\"utf-8\", na_values=[\"\",\"NA\",\"NaN\",\"N/A\"])\n",
    "print(\"Raw shape:\", df.shape)\n",
    "\n",
    "df.columns = [c.strip().upper().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "for col in [\"EPISODE_ID\",\"EVENT_ID\",\"DATA_SOURCE\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=col, inplace=True, errors=\"ignore\")\n",
    "\n",
    "prop_col = \"DAMAGE_PROPERTY\" if \"DAMAGE_PROPERTY\" in df.columns else None\n",
    "crop_col = \"DAMAGE_CROPS\"    if \"DAMAGE_CROPS\"    in df.columns else None\n",
    "assert prop_col and crop_col, \"Missing target columns DAMAGE_PROPERTY/DAMAGE_CROPS.\"\n",
    "\n",
    "df[\"Y_PROP\"] = df[prop_col].apply(parse_damage)\n",
    "df[\"Y_CROP\"] = df[crop_col].apply(parse_damage)\n",
    "\n",
    "df[\"EPISODE_NARRATIVE\"] = df.get(\"EPISODE_NARRATIVE\", \"\").fillna(\"\")\n",
    "df[\"EVENT_NARRATIVE\"]   = df.get(\"EVENT_NARRATIVE\", \"\").fillna(\"\")\n",
    "\n",
    "begin_ts = None; end_ts = None\n",
    "if \"BEGIN_DATE_TIME\" in df.columns and \"END_DATE_TIME\" in df.columns:\n",
    "    begin_ts = to_dt(df[\"BEGIN_DATE_TIME\"]); end_ts = to_dt(df[\"END_DATE_TIME\"])\n",
    "else:\n",
    "    begin_ts = from_ymd_time_cols(df, \"BEGIN\"); end_ts = from_ymd_time_cols(df, \"END\")\n",
    "\n",
    "df[\"DURATION_SECONDS\"] = duration_seconds(begin_ts, end_ts)\n",
    "dur_mean = df[\"DURATION_SECONDS\"].mean(skipna=True); dur_std = df[\"DURATION_SECONDS\"].std(skipna=True) or 1.0\n",
    "df[\"DURATION_SECONDS_STD\"] = (df[\"DURATION_SECONDS\"] - dur_mean) / dur_std\n",
    "\n",
    "for c in [\"BEGIN_LAT\",\"BEGIN_LON\",\"END_LAT\",\"END_LON\"]:\n",
    "    if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df[\"LAT_MEAN\"] = df[[\"BEGIN_LAT\",\"END_LAT\"]].mean(axis=1, skipna=True) if {\"BEGIN_LAT\",\"END_LAT\"}.issubset(df.columns) else df.get(\"BEGIN_LAT\", np.nan)\n",
    "df[\"LON_MEAN\"] = df[[\"BEGIN_LON\",\"END_LON\"]].mean(axis=1, skipna=True) if {\"BEGIN_LON\",\"END_LON\"}.issubset(df.columns) else df.get(\"BEGIN_LON\", np.nan)\n",
    "df[\"LAT_SIN\"] = np.sin(np.deg2rad(df[\"LAT_MEAN\"])); df[\"LAT_COS\"] = np.cos(np.deg2rad(df[\"LAT_MEAN\"]))\n",
    "df[\"LON_SIN\"] = np.sin(np.deg2rad(df[\"LON_MEAN\"])); df[\"LON_COS\"] = np.cos(np.deg2rad(df[\"LON_MEAN\"]))\n",
    "\n",
    "for side in [\"BEGIN\",\"END\"]:\n",
    "    azc = f\"{side}_AZIMUTH\"\n",
    "    if azc in df.columns: df[f\"{azc}_DEG\"] = df[azc].astype(str).str.upper().map(AZIMUTH_MAP)\n",
    "\n",
    "if {\"BEGIN_AZIMUTH_DEG\",\"END_AZIMUTH_DEG\"}.issubset(df.columns):\n",
    "    df[\"AZIMUTH_DEG_MEAN\"] = df[[\"BEGIN_AZIMUTH_DEG\",\"END_AZIMUTH_DEG\"]].mean(axis=1)\n",
    "    rad = np.deg2rad(df[\"AZIMUTH_DEG_MEAN\"]); df[\"AZIMUTH_SIN\"] = np.sin(rad); df[\"AZIMUTH_COS\"] = np.cos(rad)\n",
    "\n",
    "if {\"BEGIN_RANGE\",\"END_RANGE\"}.issubset(df.columns):\n",
    "    df[\"RANGE_MEAN\"] = pd.to_numeric(df[\"BEGIN_RANGE\"], errors=\"coerce\").add(pd.to_numeric(df[\"END_RANGE\"], errors=\"coerce\")) / 2.0\n",
    "\n",
    "df[\"LOCATION_NAME\"] = df.get(\"BEGIN_LOCATION\", pd.Series(index=df.index)).fillna(df.get(\"END_LOCATION\",\"\"))\n",
    "\n",
    "for c in [\"BEGIN_LAT\",\"BEGIN_LON\",\"END_LAT\",\"END_LON\",\"BEGIN_AZIMUTH\",\"END_AZIMUTH\",\"BEGIN_LOCATION\",\"END_LOCATION\",\"BEGIN_RANGE\",\"END_RANGE\"]:\n",
    "    if c in df.columns: df.drop(columns=c, inplace=True, errors=\"ignore\")\n",
    "\n",
    "if prop_col in df.columns: df.drop(columns=prop_col, inplace=True, errors=\"ignore\")\n",
    "if crop_col in df.columns: df.drop(columns=crop_col, inplace=True, errors=\"ignore\")\n",
    "\n",
    "snapshot = {\"rows\": int(len(df)), \"cols\": int(len(df.columns)), \"missing_Y_PROP\": int(df[\"Y_PROP\"].isna().sum()), \"missing_Y_CROP\": int(df[\"Y_CROP\"].isna().sum())}\n",
    "json.dump(snapshot, open(os.path.join(OUTDIR,\"data_snapshot.json\"),\"w\"), indent=2)\n",
    "\n",
    "print(\"Clean shape:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad98e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 4) Feature sets & splits ===\n",
    "text_cols = [c for c in [\"EPISODE_NARRATIVE\",\"EVENT_NARRATIVE\"] if c in df.columns]\n",
    "cat_cols  = [c for c in [\"STATE\",\"EVENT_TYPE\",\"CZ_TYPE\",\"CZ_NAME\",\"LOCATION_NAME\"] if c in df.columns]\n",
    "num_cols  = [c for c in [\n",
    "    \"DURATION_SECONDS_STD\",\n",
    "    \"LAT_MEAN\",\"LON_MEAN\",\"LAT_SIN\",\"LAT_COS\",\"LON_SIN\",\"LON_COS\",\n",
    "    \"AZIMUTH_DEG_MEAN\",\"AZIMUTH_SIN\",\"AZIMUTH_COS\",\n",
    "    \"INJURIES_DIRECT\",\"INJURIES_INDIRECT\",\"DEATHS_DIRECT\",\"DEATHS_INDIRECT\"\n",
    "] if c in df.columns]\n",
    "\n",
    "print(\"text_cols:\", text_cols)\n",
    "print(\"cat_cols :\", cat_cols)\n",
    "print(\"num_cols :\", len(num_cols))\n",
    "\n",
    "df_model = df.dropna(subset=[\"Y_PROP\",\"Y_CROP\"]).copy()\n",
    "y = np.column_stack([df_model[\"Y_PROP\"].values, df_model[\"Y_CROP\"].values]); y_log = np.log1p(y)\n",
    "X = df_model[num_cols + cat_cols + text_cols].copy()\n",
    "\n",
    "X_train, X_temp, y_train_log, y_temp_log = train_test_split(X, y_log, test_size=0.30, random_state=42)\n",
    "X_valid, X_test, y_valid_log, y_test_log = train_test_split(X_temp, y_temp_log, test_size=0.50, random_state=42)\n",
    "print(\"Sizes -> Train:\", len(X_train), \"| Valid:\", len(X_valid), \"| Test:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86933296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 5) Preprocessing ===\n",
    "class SBERTEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\", device=None, batch_size=64):\n",
    "        self.model_name = model_name; self.device = device; self.batch_size = batch_size\n",
    "        self._model = None\n",
    "    def _lazy_model(self):\n",
    "        if self._model is None:\n",
    "            self._model = SentenceTransformer(self.model_name, device=self.device if self.device else None)\n",
    "        return self._model\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        m = self._lazy_model()\n",
    "        if isinstance(X, pd.DataFrame): texts = X.iloc[:,0].astype(str).fillna(\"\").tolist()\n",
    "        elif isinstance(X, pd.Series): texts = X.astype(str).fillna(\"\").tolist()\n",
    "        else: texts = pd.Series(X).astype(str).fillna(\"\").tolist()\n",
    "        return m.encode(texts, batch_size=self.batch_size, show_progress_bar=False, convert_to_numpy=True, normalize_embeddings=False)\n",
    "\n",
    "num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),(\"scaler\", StandardScaler())])\n",
    "cat_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))])\n",
    "\n",
    "transformers = []\n",
    "if num_cols: transformers.append((\"num\", num_pipe, num_cols))\n",
    "if cat_cols: transformers.append((\"cat\", cat_pipe, cat_cols))\n",
    "for tc in text_cols:\n",
    "    transformers.append((f\"text_{tc.lower()}\", Pipeline([(\"sbert\", SBERTEncoder())]), [tc]))\n",
    "\n",
    "preprocess = ColumnTransformer(transformers, remainder=\"drop\", n_jobs=None)\n",
    "print(\"Preprocessing ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 6) Models ===\n",
    "def make_ridge(alpha=1.0):\n",
    "    return MultiOutputRegressor(Ridge(alpha=alpha, random_state=42))\n",
    "\n",
    "def make_xgb(n_estimators=300, max_depth=6, learning_rate=0.05):\n",
    "    est = XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate,\n",
    "                       subsample=0.9, colsample_bytree=0.9, random_state=42, n_jobs=-1, tree_method='hist', reg_lambda=1.0)\n",
    "    return MultiOutputRegressor(est)\n",
    "\n",
    "USE_RTDL_FLAG = USE_RTDL\n",
    "if USE_RTDL_FLAG:\n",
    "    import torch, torch.nn as nn, torch.optim as optim, rtdl\n",
    "\n",
    "class TorchTabTransformerRegressor(BaseEstimator):\n",
    "    def __init__(self, epochs=10, lr=1e-3, batch_size=256, device=None):\n",
    "        self.epochs = epochs; self.lr = lr; self.batch_size = batch_size\n",
    "        self.device = device or (\"cuda\" if (USE_RTDL_FLAG and torch.cuda.is_available()) else \"cpu\")\n",
    "        self.model = None\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X); y = np.array(y, dtype=np.float32)\n",
    "        n, d = X.shape; ydim = y.shape[1] if y.ndim > 1 else 1\n",
    "        model = rtdl.FTTransformer.make_default(n_num_features=d, cat_cardinalities=None, last_layer_query_idx=[-1],\n",
    "                                                d_token=192, n_blocks=2, attention_dropout=0.2, ff_dropout=0.2, d_out=ydim).to(self.device)\n",
    "        opt = optim.Adam(model.parameters(), lr=self.lr); loss_fn = nn.MSELoss()\n",
    "        dl = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
    "                                                                        torch.tensor(y, dtype=torch.float32)),\n",
    "                                         batch_size=self.batch_size, shuffle=True)\n",
    "        model.train()\n",
    "        for _ in range(self.epochs):\n",
    "            for xb, yb in dl:\n",
    "                xb = xb.to(self.device); yb = yb.to(self.device)\n",
    "                opt.zero_grad(); pred = model(xb); loss = loss_fn(pred, yb)\n",
    "                loss.backward(); opt.step()\n",
    "        self.model = model; return self\n",
    "    def predict(self, X):\n",
    "        X = np.array(X); self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            xb = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            return self.model(xb).cpu().numpy()\n",
    "\n",
    "def make_tabtr(epochs=10, lr=1e-3):\n",
    "    if USE_RTDL_FLAG:\n",
    "        return TorchTabTransformerRegressor(epochs=epochs, lr=lr)\n",
    "    else:\n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        return MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(256,128), activation='relu', random_state=42, max_iter=200))\n",
    "\n",
    "print(\"Models ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 7) First-pass evaluation ===\n",
    "def eval_on_split(pipe, Xtr, ytr_log, Xev, yev_log, label):\n",
    "    pipe.fit(Xtr, ytr_log)\n",
    "    pred_log = pipe.predict(Xev)\n",
    "    yhat = np.expm1(pred_log); ytrue = np.expm1(yev_log)\n",
    "    mf = metrics_frame(ytrue, yhat, [\"damage_property\",\"damage_crops\"])\n",
    "    print(f\"\\\\nüìä {label} results:\\\\n{mf}\")\n",
    "    return mf, yhat\n",
    "\n",
    "pipes = {\n",
    "    \"ridge\": Pipeline([(\"prep\", preprocess), (\"reg\", make_ridge(alpha=1.0))]),\n",
    "    \"xgb\":   Pipeline([(\"prep\", preprocess), (\"reg\", make_xgb())]),\n",
    "    \"tabtr\": Pipeline([(\"prep\", preprocess), (\"reg\", make_tabtr(epochs=10, lr=1e-3))])\n",
    "}\n",
    "val_results = {}\n",
    "for name, pipe in pipes.items():\n",
    "    mf, _ = eval_on_split(pipe, X_train, y_train_log, X_valid, y_valid_log, f\"{name} (validation)\")\n",
    "    val_results[name] = mf\n",
    "json.dump({k: v.to_dict(orient=\"index\") for k, v in val_results.items()}, open(os.path.join(OUTDIR,\"validation_metrics_first_pass.json\"),\"w\"), indent=2)\n",
    "print(\"‚úì Saved first-pass metrics.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c03de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 8) Optuna tuning ===\n",
    "def rmse_sum_pred(y_true_log, y_pred_log):\n",
    "    yt = np.expm1(y_true_log); yp = np.expm1(y_pred_log)\n",
    "    return math.sqrt(mean_squared_error(yt[:,0], yp[:,0])) + math.sqrt(mean_squared_error(yt[:,1], yp[:,1]))\n",
    "\n",
    "def objective_factory(model_name):\n",
    "    def objective(trial):\n",
    "        if model_name == \"ridge\":\n",
    "            alpha = trial.suggest_float(\"alpha\", 0.01, 200.0, log=True)\n",
    "            model = make_ridge(alpha=alpha)\n",
    "        elif model_name == \"xgb\":\n",
    "            n_estimators = trial.suggest_int(\"n_estimators\", 200, 800, step=100)\n",
    "            max_depth    = trial.suggest_int(\"max_depth\", 3, 9, step=1)\n",
    "            learning_rate= trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "            model = make_xgb(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
    "        elif model_name == \"tabtr\":\n",
    "            epochs = trial.suggest_int(\"epochs\", 8, 20, step=4)\n",
    "            lr     = trial.suggest_float(\"lr\", 5e-4, 2e-3, log=True)\n",
    "            model  = make_tabtr(epochs=epochs, lr=lr)\n",
    "        pipe = Pipeline([(\"prep\", preprocess), (\"reg\", model)])\n",
    "        pipe.fit(X_train, y_train_log)\n",
    "        pred = pipe.predict(X_valid)\n",
    "        return rmse_sum_pred(y_valid_log, pred)\n",
    "    return objective\n",
    "\n",
    "best_params = {}\n",
    "for name in [\"ridge\",\"xgb\",\"tabtr\"]:\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=f\"{name}_tuning\")\n",
    "    study.optimize(objective_factory(name), n_trials=15, show_progress_bar=False)\n",
    "    best_params[name] = study.best_params\n",
    "    print(f\"Best {name} params:\", study.best_params, \"-> score:\", study.best_value)\n",
    "\n",
    "pd.DataFrame(best_params).to_csv(os.path.join(OUTDIR,\"best_hyperparams.csv\"))\n",
    "json.dump(best_params, open(os.path.join(OUTDIR,\"best_hyperparams.json\"),\"w\"), indent=2)\n",
    "print(\"‚úì Saved best_hyperparams.csv/.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 9) Winner + Permutation Importance + Top‚Äë20 + Test ===\n",
    "tuned = json.load(open(os.path.join(OUTDIR,\"best_hyperparams.json\")))\n",
    "pipes_tuned = {\n",
    "    \"ridge\": Pipeline([(\"prep\", preprocess), (\"reg\", make_ridge(**tuned.get(\"ridge\", {\"alpha\":1.0}))) ]),\n",
    "    \"xgb\":   Pipeline([(\"prep\", preprocess), (\"reg\", make_xgb(**tuned.get(\"xgb\", {}))) ]),\n",
    "    \"tabtr\": Pipeline([(\"prep\", preprocess), (\"reg\", make_tabtr(**tuned.get(\"tabtr\", {}))) ])\n",
    "}\n",
    "val_tuned = {}\n",
    "for name, pipe in pipes_tuned.items():\n",
    "    mf, _ = eval_on_split(pipe, X_train, y_train_log, X_valid, y_valid_log, f\"{name} tuned (validation)\")\n",
    "    val_tuned[name] = mf\n",
    "\n",
    "def rmse_sum_from_df(dfm): return float(dfm[\"RMSE\"].sum())\n",
    "winner = min(val_tuned.keys(), key=lambda n: rmse_sum_from_df(val_tuned[n]))\n",
    "print(\"üèÜ Winner after tuning:\", winner)\n",
    "\n",
    "best_pipe = pipes_tuned[winner]; best_pipe.fit(X_train, y_train_log)\n",
    "Xt_train = best_pipe.named_steps[\"prep\"].transform(X_train)\n",
    "Xt_valid = best_pipe.named_steps[\"prep\"].transform(X_valid)\n",
    "final_est = best_pipe.named_steps[\"reg\"]\n",
    "\n",
    "def train_single_target_estimator(est, Xt, y_log, i):\n",
    "    if isinstance(est, MultiOutputRegressor):\n",
    "        base = clone(est.estimators_[0])\n",
    "    else:\n",
    "        base = clone(est)\n",
    "    base.fit(Xt, y_log[:, i]); return base\n",
    "\n",
    "m0 = train_single_target_estimator(final_est, Xt_train, y_train_log, 0)\n",
    "m1 = train_single_target_estimator(final_est, Xt_train, y_train_log, 1)\n",
    "perm1 = permutation_importance(m0, Xt_valid, y_valid_log[:,0], n_repeats=5, random_state=42, n_jobs=-1)\n",
    "perm2 = permutation_importance(m1, Xt_valid, y_valid_log[:,1], n_repeats=5, random_state=42, n_jobs=-1)\n",
    "imp_mean = (perm1.importances_mean + perm2.importances_mean) / 2.0\n",
    "\n",
    "feat_names=[]\n",
    "for name, trans, cols in best_pipe.named_steps[\"prep\"].transformers_:\n",
    "    if name==\"num\": feat_names.extend(cols)\n",
    "    elif name==\"cat\":\n",
    "        ohe = trans.named_steps.get(\"onehot\", None)\n",
    "        if ohe is not None:\n",
    "            try: fn = ohe.get_feature_names_out(cols)\n",
    "            except: fn = ohe.get_feature_names_out()\n",
    "            feat_names.extend(fn.tolist())\n",
    "    elif name.startswith(\"text_\"):\n",
    "        dummy = trans.transform(pd.DataFrame({cols[0]: [\"sample\"]})); dim = dummy.shape[1]\n",
    "        feat_names.extend([f\"{name}_emb_{i}\" for i in range(dim)])\n",
    "if len(feat_names)!=Xt_valid.shape[1]: feat_names=[f\"f_{i}\" for i in range(Xt_valid.shape[1])]\n",
    "\n",
    "rank=np.argsort(imp_mean)[::-1]; top_k=20; top_idx=rank[:top_k]\n",
    "importances = pd.DataFrame({\"feature\":[feat_names[i] for i in top_idx], \"importance\":[float(imp_mean[i]) for i in top_idx]})\n",
    "importances.to_csv(os.path.join(OUTDIR,\"top20_features.csv\"), index=False); print(importances.head())\n",
    "\n",
    "def select_columns_by_idx(Xm): return Xm[:, top_idx]\n",
    "feature_selector = FunctionTransformer(select_columns_by_idx, validate=False)\n",
    "\n",
    "pipe_top20 = Pipeline([(\"prep\", preprocess), (\"select\", feature_selector), (\"reg\", final_est)]); pipe_top20.fit(X_train, y_train_log)\n",
    "\n",
    "def test_report(pipe, tag):\n",
    "    yhat = np.expm1(pipe.predict(X_test)); ytrue = np.expm1(y_test_log)\n",
    "    mf = metrics_frame(ytrue, yhat, [\"damage_property\",\"damage_crops\"])\n",
    "    print(f\"\\\\n=== TEST REPORT: {tag} ===\\\\n\", mf); return mf\n",
    "\n",
    "mf_top20_best = test_report(pipe_top20, f\"Top-20 winner = {winner}\")\n",
    "json.dump({\"top20_best\": mf_top20_best.to_dict(orient=\"index\")}, open(os.path.join(OUTDIR,\"test_metrics.json\"),\"w\"), indent=2)\n",
    "joblib.dump({\"pipeline\": pipe_top20, \"feature_space\":\"top20\", \"top20_indices\": top_idx.tolist(), \"text_model\": \"all-MiniLM-L6-v2\", \"targets\":[\"Y_PROP\",\"Y_CROP\"]}, os.path.join(OUTDIR,\"damage_pipeline_best.joblib\"))\n",
    "print(\"‚úì Saved final model to damage_pipeline_best.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 10) SHAP Explainability ===\n",
    "bundle = joblib.load(os.path.join(OUTDIR, \"damage_pipeline_best.joblib\")); best_pipe = bundle[\"pipeline\"]\n",
    "\n",
    "X_sample = X_valid.sample(min(200, len(X_valid)), random_state=42)\n",
    "X_prep = best_pipe.named_steps[\"prep\"].transform(X_sample)\n",
    "final_est = best_pipe.named_steps[\"reg\"]\n",
    "\n",
    "explainer = None; shap_values = None; feat_names=[]\n",
    "for name, trans, cols in best_pipe.named_steps[\"prep\"].transformers_:\n",
    "    if name==\"num\": feat_names.extend(cols)\n",
    "    elif name==\"cat\":\n",
    "        ohe = trans.named_steps.get(\"onehot\", None)\n",
    "        if ohe is not None:\n",
    "            try: fn = ohe.get_feature_names_out(cols)\n",
    "            except: fn = ohe.get_feature_names_out()\n",
    "            feat_names.extend(fn.tolist())\n",
    "    elif name.startswith(\"text_\"):\n",
    "        dummy = trans.transform(pd.DataFrame({cols[0]: [\"sample\"]})); dim = dummy.shape[1]\n",
    "        feat_names.extend([f\"{name}_emb_{i}\" for i in range(dim)])\n",
    "\n",
    "try:\n",
    "    if isinstance(final_est, MultiOutputRegressor):\n",
    "        expl0 = shap.Explainer(final_est.estimators_[0], X_prep); sv0 = expl0(X_prep)\n",
    "        expl1 = shap.Explainer(final_est.estimators_[1], X_prep); sv1 = expl1(X_prep)\n",
    "        shap_values = np.stack([sv0.values, sv1.values], axis=2)  # [n,f,2]\n",
    "    else:\n",
    "        expl = shap.Explainer(final_est, X_prep); sv = expl(X_prep)\n",
    "        shap_values = sv\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è SHAP failed:\", e)\n",
    "\n",
    "if shap_values is not None:\n",
    "    if isinstance(shap_values, np.ndarray) and shap_values.ndim==3:\n",
    "        mean_abs = np.mean(np.abs(shap_values), axis=(0,2))\n",
    "    else:\n",
    "        vals = shap_values.values if hasattr(shap_values, \"values\") else None\n",
    "        mean_abs = np.mean(np.abs(vals), axis=0) if vals is not None else None\n",
    "\n",
    "    if mean_abs is not None:\n",
    "        shap_df = pd.DataFrame({\"feature\": feat_names, \"mean_abs_shap\": mean_abs}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "        shap_df.to_csv(os.path.join(OUTDIR, \"shap_importance.csv\"), index=False)\n",
    "\n",
    "        plt.figure(figsize=(8,5))\n",
    "        idx = np.argsort(mean_abs)[-20:][::-1]\n",
    "        plt.barh([feat_names[i] for i in idx][::-1], mean_abs[idx][::-1])\n",
    "        plt.xlabel(\"Mean |SHAP|\"); plt.title(\"Top 20 Global Features (SHAP)\")\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(OUTDIR,\"shap_barplot_global.png\"), dpi=300); plt.close()\n",
    "\n",
    "        if isinstance(shap_values, np.ndarray) and shap_values.ndim==3:\n",
    "            for ti, tname in enumerate([\"damage_property\",\"damage_crops\"]):\n",
    "                try:\n",
    "                    plt.figure(figsize=(8,5))\n",
    "                    shap.summary_plot(shap_values[...,ti], X_prep, feature_names=feat_names, show=False)\n",
    "                    plt.title(f\"SHAP Summary ‚Äî {tname}\")\n",
    "                    plt.savefig(os.path.join(OUTDIR, f\"shap_beeswarm_{tname}.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "                except Exception as e:\n",
    "                    print(\"Beeswarm failed:\", e)\n",
    "        else:\n",
    "            try:\n",
    "                plt.figure(figsize=(8,5))\n",
    "                shap.summary_plot(shap_values, X_prep, feature_names=feat_names, show=False)\n",
    "                plt.title(\"SHAP Summary\")\n",
    "                plt.savefig(os.path.join(OUTDIR, \"shap_beeswarm_generic.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(\"Beeswarm generic failed:\", e)\n",
    "\n",
    "print(\"SHAP artifacts done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 11) LLM explanations + combined CSV ===\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def llm_explain_shap_for_sample(top_pairs, model_name=\"gpt-4-turbo\"):\n",
    "    if not OPENAI_READY:\n",
    "        parts = [f\"{f} ({v:+.3f})\" for f, v in top_pairs]\n",
    "        return (\"Model predicts higher/lower damages primarily due to: \" +\n",
    "                \", \".join(parts) +\n",
    "                \". Text embeddings reflect severity/impact cues; geospatial and duration features modulate exposure.\")\n",
    "    try:\n",
    "        client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        prompt = f\\\"\\\"\\\"Explain, in 3‚Äì5 sentences, why the following features and SHAP values\n",
    "increase/decrease predicted storm damages (property/crops). Be concise.\n",
    "Features: {top_pairs}\\\"\\\"\\\"\n",
    "        resp = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\":\"system\",\"content\":\"You are a precise data scientist writing model explanations.\"},\n",
    "                {\"role\":\"user\",\"content\":prompt}\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"LLM unavailable: {e}\"\n",
    "\n",
    "combined_rows = []\n",
    "try:\n",
    "    if isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
    "        mean_abs_sample = np.mean(np.abs(shap_values), axis=2)  # [n, f]\n",
    "        for i in range(min(10, mean_abs_sample.shape[0])):\n",
    "            order = np.argsort(-mean_abs_sample[i])[:5]\n",
    "            pairs_mean = [(feat_names[j], float(np.mean(shap_values[i, j, :]))) for j in order]\n",
    "            llm_text = llm_explain_shap_for_sample(pairs_mean)\n",
    "            for j in order:\n",
    "                combined_rows.append({\"sample_id\": i, \"feature\": feat_names[j], \"shap_value\": float(np.mean(shap_values[i, j, :])), \"llm_summary\": llm_text})\n",
    "    else:\n",
    "        sv = shap_values.values if hasattr(shap_values, \"values\") else None\n",
    "        if sv is not None:\n",
    "            for i in range(min(10, sv.shape[0])):\n",
    "                order = np.argsort(-np.abs(sv[i]))[:5]\n",
    "                pairs = [(feat_names[j], float(sv[i, j])) for j in order]\n",
    "                llm_text = llm_explain_shap_for_sample(pairs)\n",
    "                for j in order:\n",
    "                    combined_rows.append({\"sample_id\": i, \"feature\": feat_names[j], \"shap_value\": float(sv[i, j]), \"llm_summary\": llm_text})\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Unable to build combined SHAP+LLM rows:\", e)\n",
    "\n",
    "combined_df = pd.DataFrame(combined_rows)\n",
    "combined_path = os.path.join(OUTDIR, \"combined_shap_llm_report.csv\")\n",
    "combined_df.to_csv(combined_path, index=False)\n",
    "print(\"‚úì Saved combined SHAP + LLM report ->\", combined_path)\n",
    "\n",
    "for sid in sorted(combined_df[\"sample_id\"].unique())[:3]:\n",
    "    sub = combined_df[combined_df[\"sample_id\"] == sid]\n",
    "    md = f\"### üå©Ô∏è Event {sid} ‚Äî Top Feature Drivers\\\\n\"\n",
    "    for _, row in sub.iterrows():\n",
    "        sign = \"‚¨ÜÔ∏è\" if row[\"shap_value\"] > 0 else \"‚¨áÔ∏è\"\n",
    "        md += f\"- **{row['feature']}** ({sign}{abs(row['shap_value']):.4f})\\\\n\"\n",
    "    md += f\"\\\\n**LLM Explanation:** {sub.iloc[0]['llm_summary']}\\\\n\"\n",
    "    display(Markdown(md))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a21586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 12) Executive Summary (LLM or fallback) ===\n",
    "from datetime import datetime\n",
    "from textwrap import shorten\n",
    "\n",
    "metrics_path = os.path.join(OUTDIR, \"test_metrics.json\")\n",
    "shap_path    = os.path.join(OUTDIR, \"shap_importance.csv\")\n",
    "local_path   = os.path.join(OUTDIR, \"combined_shap_llm_report.csv\")\n",
    "summary_txt  = os.path.join(OUTDIR, \"executive_summary.txt\")\n",
    "snapshot_json= os.path.join(OUTDIR, \"data_snapshot.json\")\n",
    "\n",
    "metrics = json.load(open(metrics_path)) if os.path.exists(metrics_path) else None\n",
    "shap_top = pd.read_csv(shap_path).head(10) if os.path.exists(shap_path) else pd.DataFrame(columns=[\"feature\",\"mean_abs_shap\"])\n",
    "local_df = pd.read_csv(local_path) if os.path.exists(local_path) else pd.DataFrame(columns=[\"sample_id\",\"feature\",\"shap_value\",\"llm_summary\"])\n",
    "snapshot = json.load(open(snapshot_json)) if os.path.exists(snapshot_json) else {\"rows\":None,\"cols\":None}\n",
    "\n",
    "def build_prompt(perf_lines, feat_lines, examples, snapshot):\n",
    "    return f\\\"\\\"\\\"You are a senior data scientist. Write an executive summary (150‚Äì220 words) about a storm-damage model\n",
    "(two targets: damage_property, damage_crops) using structured and text features embedded by a pretrained SentenceTransformer.\n",
    "\n",
    "Data snapshot: rows={snapshot.get('rows')}, cols={snapshot.get('cols')}, missing_Y_PROP={snapshot.get('missing_Y_PROP')}, missing_Y_CROP={snapshot.get('missing_Y_CROP')}.\n",
    "\n",
    "Performance (test):\n",
    "{os.linesep.join(perf_lines) if perf_lines else \"- (no metrics found)\"}\n",
    "\n",
    "Top global features (mean |SHAP|):\n",
    "{os.linesep.join(feat_lines) if feat_lines else \"- (no SHAP found)\"}\n",
    "\n",
    "Examples:\n",
    "{os.linesep.join(examples) if examples else \"- (no examples)\"}\n",
    "\n",
    "Include: What was modeled and why, performance meaning, key drivers (incl. narratives), limitations, and next steps.\n",
    "Return 1‚Äì2 cohesive paragraphs (no bullets).\\\"\\\"\\\"\n",
    "\n",
    "def heuristic_summary(perf_lines, feat_lines, snapshot):\n",
    "    perf = \"\\\\n\".join(perf_lines) if perf_lines else \"No test-set metrics available.\"\n",
    "    feats = \", \".join([r.feature for _, r in shap_top.iterrows()]) if len(shap_top) else \"no dominant features identified\"\n",
    "    return (f\"This report describes a two-target regression system predicting property and crop damages from storm events, \"\n",
    "            f\"combining structured variables with narrative embeddings from a pretrained SentenceTransformer. The dataset \"\n",
    "            f\"contained roughly {snapshot.get('rows')} rows and {snapshot.get('cols')} columns. Test-set performance was:\\\\n{perf}\\\\n\\\\n\"\n",
    "            f\"Global explainability indicates the model relies most on {feats}. Local analyses show that narrative cues about \"\n",
    "            f\"structural destruction, flooding, and prolonged duration align with higher predicted losses, while location and \"\n",
    "            f\"event-type effects capture exposure and hazard intensity. Limitations include potential noise or sparsity in text \"\n",
    "            f\"fields, coarse geospatial resolution, and limited representation of small-to-medium events. Recommended next steps \"\n",
    "            f\"include incorporating exposure/asset data (e.g., building density), richer geospatial covariates, and additional \"\n",
    "            f\"training data to improve stability and calibration.\")\n",
    "\n",
    "perf_lines = []\n",
    "if metrics and \"top20_best\" in metrics:\n",
    "    mdf = pd.DataFrame(metrics[\"top20_best\"]).T[[\"MAE\",\"RMSE\",\"R2\"]]\n",
    "    for target, row in mdf.iterrows():\n",
    "        perf_lines.append(f\"- {target}: MAE={row['MAE']:.0f}, RMSE={row['RMSE']:.0f}, R¬≤={row['R2']:.3f}\")\n",
    "feat_lines = [f\"- {r.feature}: {r.mean_abs_shap:.4f}\" for _, r in shap_top.iterrows()]\n",
    "\n",
    "examples = []\n",
    "if not local_df.empty:\n",
    "    for sid in sorted(local_df[\"sample_id\"].unique())[:3]:\n",
    "        chunk = local_df[local_df[\"sample_id\"] == sid].sort_values(\"shap_value\", key=np.abs, ascending=False).head(3)\n",
    "        tops = \"; \".join([f\"{r.feature} ({r.shap_value:+.3f})\" for _, r in chunk.iterrows()])\n",
    "        txt  = shorten(str(chunk.iloc[0][\"llm_summary\"]), width=300, placeholder=\"‚Ä¶\")\n",
    "        examples.append(f\"‚Ä¢ Event {sid}: {tops} ‚Äî {txt}\")\n",
    "\n",
    "if OPENAI_READY:\n",
    "    try:\n",
    "        client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        prompt = build_prompt(perf_lines, feat_lines, examples, snapshot)\n",
    "        resp = client.chat.completions.create(model=\"gpt-4-turbo\",\n",
    "            messages=[{\"role\":\"system\",\"content\":\"You are a careful, precise data scientist writing executive summaries.\"},\n",
    "                      {\"role\":\"user\",\"content\":prompt}], temperature=0.2)\n",
    "        summary_text = resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(\"LLM failed, fallback:\", e); summary_text = heuristic_summary(perf_lines, feat_lines, snapshot)\n",
    "else:\n",
    "    summary_text = heuristic_summary(perf_lines, feat_lines, snapshot)\n",
    "\n",
    "with open(summary_txt, \"w\", encoding=\"utf-8\") as f: f.write(summary_text)\n",
    "print(\"‚úì Executive summary saved to:\", summary_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 13) PDF Generation ===\n",
    "import datetime\n",
    "\n",
    "pdf_path = os.path.join(OUTDIR, \"storm_damage_explainability_report.pdf\")\n",
    "styles = getSampleStyleSheet()\n",
    "doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
    "story = []\n",
    "\n",
    "exec_path = os.path.join(OUTDIR, \"executive_summary.txt\")\n",
    "if os.path.exists(exec_path):\n",
    "    story.append(Paragraph(\"<b>Executive Summary</b>\", styles[\"Heading1\"])); story.append(Spacer(1,10))\n",
    "    for para in open(exec_path, \"r\", encoding=\"utf-8\").read().strip().split(\"\\\\n\\\\n\"):\n",
    "        story.append(Paragraph(para.strip(), styles[\"BodyText\"])); story.append(Spacer(1,10))\n",
    "    story.append(Spacer(1,18))\n",
    "\n",
    "story.append(Paragraph(\"<b>Storm Damage Prediction ‚Äì Explainability Report</b>\", styles[\"Title\"]))\n",
    "story.append(Spacer(1, 12))\n",
    "story.append(Paragraph(f\"Generated on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", styles[\"Normal\"]))\n",
    "story.append(Spacer(1, 18))\n",
    "\n",
    "test_metrics_path = os.path.join(OUTDIR, \"test_metrics.json\")\n",
    "if os.path.exists(test_metrics_path):\n",
    "    story.append(Paragraph(\"<b>Model Performance on Test Set</b>\", styles[\"Heading2\"]))\n",
    "    metrics = json.load(open(test_metrics_path))\n",
    "    metrics_df = pd.DataFrame(metrics[\"top20_best\"]).T.reset_index().rename(columns={\"index\":\"Target\"})\n",
    "    table_data = [list(metrics_df.columns)] + metrics_df.values.tolist()\n",
    "    table = Table(table_data, hAlign=\"LEFT\")\n",
    "    table.setStyle(TableStyle([(\"BACKGROUND\",(0,0),(-1,0), colors.HexColor(\"#003366\")),\n",
    "                               (\"TEXTCOLOR\",(0,0),(-1,0), colors.whitesmoke),\n",
    "                               (\"ALIGN\",(0,0),(-1,-1),\"CENTER\"),\n",
    "                               (\"GRID\",(0,0),(-1,-1),0.25, colors.grey),\n",
    "                               (\"FONTNAME\",(0,0),(-1,0),\"Helvetica-Bold\")]))\n",
    "    story.append(table); story.append(Spacer(1,18))\n",
    "\n",
    "shap_csv = os.path.join(OUTDIR, \"shap_importance.csv\")\n",
    "combined_path = os.path.join(OUTDIR, \"combined_shap_llm_report.csv\")\n",
    "assert os.path.exists(shap_csv) and os.path.exists(combined_path), \"Run SHAP + LLM blocks first.\"\n",
    "\n",
    "shap_df = pd.read_csv(shap_csv).head(20)\n",
    "bar_plot_path = os.path.join(OUTDIR, \"shap_barplot_global.png\")\n",
    "\n",
    "story.append(Paragraph(\"<b>Global Feature Importance (SHAP)</b>\", styles[\"Heading2\"]))\n",
    "tdata = [list(shap_df.columns)] + shap_df.values.tolist()\n",
    "table = Table(tdata, hAlign=\"LEFT\")\n",
    "table.setStyle(TableStyle([(\"BACKGROUND\",(0,0),(-1,0), colors.HexColor(\"#003366\")),\n",
    "                           (\"TEXTCOLOR\",(0,0),(-1,0), colors.whitesmoke),\n",
    "                           (\"ALIGN\",(0,0),(-1,-1),\"CENTER\"),\n",
    "                           (\"GRID\",(0,0),(-1,-1),0.25, colors.grey),\n",
    "                           (\"FONTNAME\",(0,0),(-1,0),\"Helvetica-Bold\")]))\n",
    "story.append(table); story.append(Spacer(1,12))\n",
    "\n",
    "if os.path.exists(bar_plot_path):\n",
    "    story.append(Paragraph(\"<b>Global SHAP Bar Chart</b>\", styles[\"Heading3\"]))\n",
    "    story.append(Image(bar_plot_path, width=400, height=250)); story.append(Spacer(1,12))\n",
    "\n",
    "for tname in [\"damage_property\",\"damage_crops\",\"shap_beeswarm_generic\"]:\n",
    "    p = os.path.join(OUTDIR, f\"shap_beeswarm_{tname}.png\") if \"generic\" not in tname else os.path.join(OUTDIR, \"shap_beeswarm_generic.png\")\n",
    "    if os.path.exists(p):\n",
    "        title = f\"Beeswarm Plot ‚Äî {tname.replace('_',' ').title() if 'generic' not in tname else 'Overall'}\"\n",
    "        story.append(Paragraph(f\"<b>{title}</b>\", styles[\"Heading3\"]))\n",
    "        story.append(Image(p, width=400, height=250)); story.append(Spacer(1,12))\n",
    "\n",
    "combined_df = pd.read_csv(combined_path)\n",
    "story.append(Paragraph(\"<b>Sample-Level Interpretations</b>\", styles[\"Heading2\"]))\n",
    "for sid, group in combined_df.groupby(\"sample_id\"):\n",
    "    story.append(Paragraph(f\"<b>Event {sid} ‚Äì Local Explanation</b>\", styles[\"Heading3\"]))\n",
    "    top_feats = group[[\"feature\",\"shap_value\"]].values.tolist()\n",
    "    tdata = [[\"Feature\",\"SHAP Value\"]] + top_feats\n",
    "    table = Table(tdata, hAlign=\"LEFT\", colWidths=[220, 100])\n",
    "    table.setStyle(TableStyle([(\"BACKGROUND\",(0,0),(-1,0), colors.lightgrey),\n",
    "                               (\"GRID\",(0,0),(-1,-1),0.25, colors.grey),\n",
    "                               (\"ALIGN\",(1,1),(-1,-1),\"CENTER\")]))\n",
    "    story.append(table); story.append(Spacer(1,6))\n",
    "    story.append(Paragraph(f\"<i>{group.iloc[0]['llm_summary']}</i>\", styles[\"BodyText\"])); story.append(Spacer(1,18))\n",
    "\n",
    "doc.build(story)\n",
    "print(f\"‚úÖ Full dual-target explainability report saved at: {pdf_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}